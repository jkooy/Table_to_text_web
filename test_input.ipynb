{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_1:lenny\tname_2:randle\tposition_1:second\tposition_2:baseman\tposition_3:/\tposition_4:third\tposition_5:baseman\timage:<none>\tbats_1:switch\tthrows_1:right\tbirth_date_1:12\tbirth_date_2:february\tbirth_date_3:1949\tbirth_place_1:long\tbirth_place_2:beach\tbirth_place_3:,\tbirth_place_4:california\tdeath_date:<none>\tdeath_place:<none>\tdebutdate_1:june\tdebutdate_2:16\tdebutyear_1:1971\tdebutteam_1:washington\tdebutteam_2:senators\tfinaldate_1:june\tfinaldate_2:20\tfinalyear_1:1982\tfinalteam_1:seattle\tfinalteam_2:mariners\tstatlabel_1:batting\tstatlabel_2:average\tstatlabel_3:home\tstatlabel_4:runs\tstatlabel_5:runs\tstatlabel_6:batted\tstatlabel_7:in\tstatvalue_1:.257\tstatvalue_2:27\tstatvalue_3:322\tteams:<none>\tarticle_title_1:lenny\tarticle_title_2:randle\n",
      "['lenny', 'randle', 'second', 'baseman', '/', 'third', 'baseman', 'switch', 'right', '12', 'february', '1949', 'long', 'beach', ',', 'california', 'june', '16', '1971', 'washington', 'senators', 'june', '20', '1982', 'seattle', 'mariners', 'batting', 'average', 'home', 'runs', 'runs', 'batted', 'in', '.257', '27', '322', 'lenny', 'randle']\n",
      "['name', 'name', 'position', 'position', 'position', 'position', 'position', 'bats', 'throws', 'birth_date', 'birth_date', 'birth_date', 'birth_place', 'birth_place', 'birth_place', 'birth_place', 'debutdate', 'debutdate', 'debutyear', 'debutteam', 'debutteam', 'finaldate', 'finaldate', 'finalyear', 'finalteam', 'finalteam', 'statlabel', 'statlabel', 'statlabel', 'statlabel', 'statlabel', 'statlabel', 'statlabel', 'statvalue', 'statvalue', 'statvalue', 'article_title', 'article_title']\n",
      "[1, 2, 1, 2, 3, 4, 5, 1, 1, 1, 2, 3, 1, 2, 3, 4, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "import re, time, os\n",
    "\n",
    "fboxes = \"original_data/test.box\"\n",
    "\n",
    "mixb_word, mixb_label, mixb_pos = [], [], []\n",
    "\n",
    "box = open(fboxes, \"r\").read().strip().split('\\n')\n",
    "box_word, box_label, box_pos = [], [], []\n",
    "\n",
    "print(box[0])\n",
    "ib = box[0]\n",
    "\n",
    "item = ib.split('\\t')\n",
    "box_single_word, box_single_label, box_single_pos = [], [], []\n",
    "for it in item:\n",
    "    if len(it.split(':')) > 2:\n",
    "        continue\n",
    "    # print it\n",
    "    prefix, word = it.split(':')\n",
    "    if '<none>' in word or word.strip()=='' or prefix.strip()=='':\n",
    "        continue\n",
    "    new_label = re.sub(\"_[1-9]\\d*$\", \"\", prefix)\n",
    "    if new_label.strip() == \"\":\n",
    "        continue\n",
    "    box_single_word.append(word)\n",
    "    box_single_label.append(new_label)\n",
    "    if re.search(\"_[1-9]\\d*$\", prefix):\n",
    "        field_id = int(prefix.split('_')[-1])\n",
    "        box_single_pos.append(field_id if field_id<=30 else 30)\n",
    "    else:\n",
    "        box_single_pos.append(1)\n",
    "box_word.append(box_single_word)\n",
    "box_label.append(box_single_label)\n",
    "box_pos.append(box_single_pos)\n",
    "    \n",
    "print(box_word[0])\n",
    "print(box_label[0])\n",
    "print(box_pos[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 2, 3, 4, 5, 1, 1, 1, 2, 3, 1, 2, 3, 4, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2]\n",
      "[2, 1, 5, 4, 3, 2, 1, 1, 1, 3, 2, 1, 4, 3, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 7, 6, 5, 4, 3, 2, 1, 3, 2, 1, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "######################## reverse box #############################\n",
    "box = box_pos\n",
    "tmp_pos = []\n",
    "single_pos = []\n",
    "reverse_pos = []\n",
    "for pos in box:\n",
    "    print(pos)\n",
    "    tmp_pos = []\n",
    "    single_pos = []\n",
    "    for p in pos:\n",
    "        if int(p) == 1 and len(tmp_pos) != 0:\n",
    "            single_pos.extend(tmp_pos[::-1])\n",
    "            tmp_pos = []\n",
    "        tmp_pos.append(p)\n",
    "    single_pos.extend(tmp_pos[::-1])\n",
    "    reverse_pos=single_pos\n",
    "\n",
    "print(reverse_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10413, 3, 106, 1753, 1358, 324, 1753, 7391, 710, 174, 77, 565, 569, 1526, 4, 260, 69, 199, 418, 400, 2320, 69, 180, 317, 1359, 3618, 1130, 675, 382, 447, 447, 1291, 7, 3, 234, 3, 10413, 3]\n",
      "[6, 6, 14, 14, 14, 14, 14, 113, 112, 5, 5, 5, 7, 7, 7, 7, 109, 109, 74, 85, 85, 133, 133, 95, 106, 106, 79, 79, 79, 79, 79, 79, 79, 80, 80, 80, 4, 4]\n",
      "[1, 2, 1, 2, 3, 4, 5, 1, 1, 1, 2, 3, 1, 2, 3, 4, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2]\n",
      "[2, 1, 5, 4, 3, 2, 1, 1, 1, 3, 2, 1, 4, 3, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 7, 6, 5, 4, 3, 2, 1, 3, 2, 1, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Vocab(object):\n",
    "    \"\"\"vocabulary for words and field types\"\"\"\n",
    "    def __init__(self):\n",
    "        vocab = dict()\n",
    "        vocab['PAD'] = 0\n",
    "        vocab['START_TOKEN'] = 1\n",
    "        vocab['END_TOKEN'] = 2\n",
    "        vocab['UNK_TOKEN'] = 3\n",
    "        cnt = 4\n",
    "        with open(\"original_data/word_vocab.txt\", \"r\") as v:\n",
    "            for line in v:\n",
    "                word = line.strip().split()[0]\n",
    "                vocab[word] = cnt\n",
    "                cnt += 1\n",
    "        self._word2id = vocab\n",
    "        self._id2word = {value: key for key, value in vocab.items()}\n",
    "\n",
    "        key_map = dict()\n",
    "        key_map['PAD'] = 0\n",
    "        key_map['START_TOKEN'] = 1\n",
    "        key_map['END_TOKEN'] = 2\n",
    "        key_map['UNK_TOKEN'] = 3\n",
    "        cnt = 4\n",
    "        with open(\"original_data/field_vocab.txt\", \"r\") as v:\n",
    "            for line in v:\n",
    "                key = line.strip().split()[0]\n",
    "                key_map[key] = cnt\n",
    "                cnt += 1\n",
    "        self._key2id = key_map\n",
    "        self._id2key = {value: key for key, value in key_map.items()}\n",
    "\n",
    "    def word2id(self, word):\n",
    "        ans = self._word2id[word] if word in self._word2id else 3\n",
    "        return ans\n",
    "\n",
    "    def id2word(self, id):\n",
    "        ans = self._id2word[int(id)]\n",
    "        return ans\n",
    "\n",
    "    def key2id(self, key):\n",
    "        ans = self._key2id[key] if key in self._key2id else 3\n",
    "        return ans\n",
    "\n",
    "    def id2key(self, id):\n",
    "        ans = self._id2key[int(id)]\n",
    "        return ans\n",
    "    \n",
    "\n",
    "vocab = Vocab()\n",
    "\n",
    "texts = \" \".join([str(vocab.word2id(word)) for word in box_word[0]]) + '\\n'\n",
    "text = list(map(int,texts.strip().split(' ')))\n",
    "print(text)\n",
    "\n",
    "fields = \" \".join([str(vocab.key2id(word)) for word in box_label[0]]) + '\\n'\n",
    "field = list(map(int,fields.strip().split(' ')))\n",
    "print(field)\n",
    "\n",
    "pos = box_pos[0]\n",
    "print(pos)\n",
    "\n",
    "rpos = reverse_pos\n",
    "print(rpos)\n",
    "\n",
    "# for k, ff in enumerate(flabs):\n",
    "#     fi = open(ff, 'r')\n",
    "#     fo = open(flabs2id[k], 'w')\n",
    "#     for line in fi:\n",
    "#         items = line.strip().split()\n",
    "#         fo.write(\" \".join([str(vocab.key2id(key)) for key in items]) + '\\n')\n",
    "#     fi.close()\n",
    "#     fo.close()\n",
    "# for k, ff in enumerate(fsums):\n",
    "#     fi = open(ff, 'r')\n",
    "#     fo = open(fsums2id[k], 'w')\n",
    "#     for line in fi:\n",
    "#         items = line.strip().split()\n",
    "#         fo.write(\" \".join([str(vocab.word2id(word)) for word in items]) + '\\n')\n",
    "#     fi.close()\n",
    "#     fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvals = ['processed_data/train/train.box.val',\n",
    "         'processed_data/test/test.box.val',\n",
    "         'processed_data/valid/valid.box.val']\n",
    "flabs = ['processed_data/train/train.box.lab',\n",
    "         'processed_data/test/test.box.lab',\n",
    "         'processed_data/valid/valid.box.lab']\n",
    "fsums = ['original_data/train.summary',\n",
    "         'original_data/test.summary',\n",
    "         'original_data/valid.summary']\n",
    "fvals2id = ['processed_data/train/train.box.val.id',\n",
    "            'processed_data/test/test.box.val.id',\n",
    "            'processed_data/valid/valid.box.val.id']\n",
    "flabs2id = ['processed_data/train/train.box.lab.id',\n",
    "            'processed_data/test/test.box.lab.id',\n",
    "            'processed_data/valid/valid.box.lab.id']\n",
    "fsums2id = ['processed_data/train/train.summary.id',\n",
    "            'processed_data/test/test.summary.id',\n",
    "            'processed_data/valid/valid.summary.id']\n",
    "vocab = Vocab()\n",
    "for k, ff in enumerate(fvals):\n",
    "    fi = open(ff, 'r')\n",
    "    fo = open(fvals2id[k], 'w')\n",
    "    for line in fi:\n",
    "        items = line.strip().split()\n",
    "        fo.write(\" \".join([str(vocab.word2id(word)) for word in items]) + '\\n')\n",
    "    fi.close()\n",
    "    fo.close()\n",
    "for k, ff in enumerate(flabs):\n",
    "    fi = open(ff, 'r')\n",
    "    fo = open(flabs2id[k], 'w')\n",
    "    for line in fi:\n",
    "        items = line.strip().split()\n",
    "        fo.write(\" \".join([str(vocab.key2id(key)) for key in items]) + '\\n')\n",
    "    fi.close()\n",
    "    fo.close()\n",
    "for k, ff in enumerate(fsums):\n",
    "    fi = open(ff, 'r')\n",
    "    fo = open(fsums2id[k], 'w')\n",
    "    for line in fi:\n",
    "        items = line.strip().split()\n",
    "        fo.write(\" \".join([str(vocab.word2id(word)) for word in items]) + '\\n')\n",
    "    fi.close()\n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, ff in enumerate(fvals):\n",
    "        fi = open(ff, 'r')\n",
    "        fo = open(fvals2id[k], 'w')\n",
    "        for line in fi:\n",
    "            items = line.strip().split()\n",
    "            fo.write(\" \".join([str(vocab.word2id(word)) for word in items]) + '\\n')\n",
    "        fi.close()\n",
    "        fo.close()\n",
    "    for k, ff in enumerate(flabs):\n",
    "        fi = open(ff, 'r')\n",
    "        fo = open(flabs2id[k], 'w')\n",
    "        for line in fi:\n",
    "            items = line.strip().split()\n",
    "            fo.write(\" \".join([str(vocab.key2id(key)) for key in items]) + '\\n')\n",
    "        fi.close()\n",
    "        fo.close()\n",
    "    for k, ff in enumerate(fsums):\n",
    "        fi = open(ff, 'r')\n",
    "        fo = open(fsums2id[k], 'w')\n",
    "        for line in fi:\n",
    "            items = line.strip().split()\n",
    "            fo.write(\" \".join([str(vocab.word2id(word)) for word in items]) + '\\n')\n",
    "        fi.close()\n",
    "        fo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
